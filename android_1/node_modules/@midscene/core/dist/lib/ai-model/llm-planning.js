"use strict";
var __webpack_require__ = {};
(()=>{
    __webpack_require__.d = (exports1, definition)=>{
        for(var key in definition)if (__webpack_require__.o(definition, key) && !__webpack_require__.o(exports1, key)) Object.defineProperty(exports1, key, {
            enumerable: true,
            get: definition[key]
        });
    };
})();
(()=>{
    __webpack_require__.o = (obj, prop)=>Object.prototype.hasOwnProperty.call(obj, prop);
})();
(()=>{
    __webpack_require__.r = (exports1)=>{
        if ('undefined' != typeof Symbol && Symbol.toStringTag) Object.defineProperty(exports1, Symbol.toStringTag, {
            value: 'Module'
        });
        Object.defineProperty(exports1, '__esModule', {
            value: true
        });
    };
})();
var __webpack_exports__ = {};
__webpack_require__.r(__webpack_exports__);
__webpack_require__.d(__webpack_exports__, {
    plan: ()=>plan
});
const img_namespaceObject = require("@midscene/shared/img");
const logger_namespaceObject = require("@midscene/shared/logger");
const utils_namespaceObject = require("@midscene/shared/utils");
const external_common_js_namespaceObject = require("../common.js");
const llm_planning_js_namespaceObject = require("./prompt/llm-planning.js");
const index_js_namespaceObject = require("./service-caller/index.js");
const debug = (0, logger_namespaceObject.getDebug)('planning');
async function plan(userInstruction, opts) {
    const { context, modelConfig, conversationHistory } = opts;
    const { screenshotBase64, size } = context;
    const { vlMode } = modelConfig;
    const systemPrompt = await (0, llm_planning_js_namespaceObject.systemPromptToTaskPlanning)({
        actionSpace: opts.actionSpace,
        vlMode,
        includeBbox: opts.includeBbox
    });
    let imagePayload = screenshotBase64;
    let imageWidth = size.width;
    let imageHeight = size.height;
    const rightLimit = imageWidth;
    const bottomLimit = imageHeight;
    if ('qwen2.5-vl' === vlMode) {
        const paddedResult = await (0, img_namespaceObject.paddingToMatchBlockByBase64)(imagePayload);
        imageWidth = paddedResult.width;
        imageHeight = paddedResult.height;
        imagePayload = paddedResult.imageBase64;
    }
    const actionContext = opts.actionContext ? `<high_priority_knowledge>${opts.actionContext}</high_priority_knowledge>\n` : '';
    const instruction = [
        {
            role: 'user',
            content: [
                {
                    type: 'text',
                    text: `${actionContext}<user_instruction>${userInstruction}</user_instruction>`
                }
            ]
        }
    ];
    let latestFeedbackMessage;
    if (conversationHistory.pendingFeedbackMessage) {
        latestFeedbackMessage = {
            role: 'user',
            content: [
                {
                    type: 'text',
                    text: `${conversationHistory.pendingFeedbackMessage}. The last screenshot is attached. Please going on according to the instruction.`
                },
                {
                    type: 'image_url',
                    image_url: {
                        url: imagePayload,
                        detail: 'high'
                    }
                }
            ]
        };
        conversationHistory.resetPendingFeedbackMessageIfExists();
    } else latestFeedbackMessage = {
        role: 'user',
        content: [
            {
                type: 'text',
                text: 'this is the latest screenshot'
            },
            {
                type: 'image_url',
                image_url: {
                    url: imagePayload,
                    detail: 'high'
                }
            }
        ]
    };
    conversationHistory.append(latestFeedbackMessage);
    const historyLog = conversationHistory.snapshot(opts.imagesIncludeCount);
    const msgs = [
        {
            role: 'system',
            content: systemPrompt
        },
        ...instruction,
        ...historyLog
    ];
    const { content: planFromAI, contentString: rawResponse, usage } = await (0, index_js_namespaceObject.callAIWithObjectResponse)(msgs, external_common_js_namespaceObject.AIActionType.PLAN, modelConfig);
    const actions = planFromAI.action ? [
        planFromAI.action
    ] : [];
    const returnValue = {
        ...planFromAI,
        actions,
        rawResponse,
        usage,
        yamlFlow: (0, external_common_js_namespaceObject.buildYamlFlowFromPlans)(actions, opts.actionSpace, planFromAI.sleep)
    };
    (0, utils_namespaceObject.assert)(planFromAI, "can't get plans from AI");
    actions.forEach((action)=>{
        const type = action.type;
        const actionInActionSpace = opts.actionSpace.find((action)=>action.name === type);
        debug('actionInActionSpace matched', actionInActionSpace);
        const locateFields = actionInActionSpace ? (0, external_common_js_namespaceObject.findAllMidsceneLocatorField)(actionInActionSpace.paramSchema) : [];
        debug('locateFields', locateFields);
        locateFields.forEach((field)=>{
            const locateResult = action.param[field];
            if (locateResult && void 0 !== vlMode) action.param[field] = (0, external_common_js_namespaceObject.fillBboxParam)(locateResult, imageWidth, imageHeight, rightLimit, bottomLimit, vlMode);
        });
    });
    if (0 === actions.length && returnValue.more_actions_needed_by_instruction && !returnValue.sleep) console.warn('No actions planned for the prompt, but model said more actions are needed:', userInstruction);
    conversationHistory.append({
        role: 'assistant',
        content: [
            {
                type: 'text',
                text: rawResponse
            }
        ]
    });
    return returnValue;
}
exports.plan = __webpack_exports__.plan;
for(var __rspack_i in __webpack_exports__)if (-1 === [
    "plan"
].indexOf(__rspack_i)) exports[__rspack_i] = __webpack_exports__[__rspack_i];
Object.defineProperty(exports, '__esModule', {
    value: true
});

//# sourceMappingURL=llm-planning.js.map